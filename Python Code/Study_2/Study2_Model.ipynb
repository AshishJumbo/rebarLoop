{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "939134e4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import lib.datautility as du\n",
    "import numpy as np\n",
    "import lib.tf_network2 as tfnet\n",
    "import lib.evaluationutility as eu\n",
    "from lib.tf_network2 import Network, Cost, Normalization, Optimizer\n",
    "import tensorflow as tf\n",
    "import session_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dedee8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile('resources/resources.zip','r') as zf:\n",
    "    zf.extractall('resources/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "537d035e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- loading resources/remnant.csv...(35.02%) "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-0fa92de56c73>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'resources/remnant.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_descriptives\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'resources/experimental.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_descriptives\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Google Drive\\iesJohannReloop\\reloopPaper\\Python Code\\Study_2\\lib\\datautility.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filename, max_rows, columns, headers, encoding, verbose)\u001b[0m\n\u001b[0;32m    214\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m'.csv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__load_csv__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_rows\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Google Drive\\iesJohannReloop\\reloopPaper\\Python Code\\Study_2\\lib\\datautility.py\u001b[0m in \u001b[0;36m__load_csv__\u001b[1;34m(filename, max_rows, columns, encoding, verbose)\u001b[0m\n\u001b[0;32m    141\u001b[0m                 \u001b[0mfilter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m             \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m             \u001b[0mna\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'#N/A'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mna\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data, headers = du.read_csv('resources/remnant.csv')\n",
    "du.print_descriptives(data, headers)\n",
    "\n",
    "data, headers = du.read_csv('resources/experimental.csv')\n",
    "du.print_descriptives(data, headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856dc238",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = [1,2,0]\n",
    "iden = [4]\n",
    "cov = [10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26]\n",
    "lab = [[3]]\n",
    "order = 7\n",
    "\n",
    "seq = tfnet.format_sequence_from_file('resources/remnant.csv',\n",
    "                                          key,lab,cov,iden,order)\n",
    "print('formatting feature columns...')\n",
    "for i in range(len(seq['x'])):\n",
    "    for j in range(len(seq['x'][i])):\n",
    "        try:\n",
    "            seq['x'][i][j] = np.array(seq['x'][i][j], dtype=np.float32)\n",
    "        except TypeError:\n",
    "            print('error...')\n",
    "            print(seq['x'][i])\n",
    "            exit(1)\n",
    "seq['x'] = tfnet.sequence_impute_missing(seq['x'])\n",
    "\n",
    "print('formatting output labels...')\n",
    "seq['y'] = tfnet.use_last_multi_label(seq['y'], 0)\n",
    "\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9c3b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = [1,2,0]\n",
    "iden = [4]\n",
    "cov = [10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26]\n",
    "lab = [[3]]\n",
    "order = 7\n",
    "\n",
    "seqex = tfnet.format_sequence_from_file('resources/experimental.csv',\n",
    "                                          key,lab,cov,iden,order)\n",
    "print('formatting feature columns...')\n",
    "for i in range(len(seqex['x'])):\n",
    "    for j in range(len(seqex['x'][i])):\n",
    "        try:\n",
    "            seqex['x'][i][j] = np.array(seqex['x'][i][j], dtype=np.float32)\n",
    "        except TypeError:\n",
    "            print('error...')\n",
    "            print(seqex['x'][i])\n",
    "            exit(1)\n",
    "seqex['x'] = tfnet.sequence_impute_missing(seqex['x'])\n",
    "\n",
    "print('formatting output labels...')\n",
    "seqex['y'] = tfnet.use_last_multi_label(seqex['y'], 0)\n",
    "\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fabf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cov = len(seq['x'][0][0])\n",
    "\n",
    "max_epochs = 200\n",
    "use_validation = True\n",
    "hidden = [50]\n",
    "batch = [64]\n",
    "layers = [1]\n",
    "keep = [.5]\n",
    "step = [1e-3]\n",
    "perf = []\n",
    "threshold = [0.0001]\n",
    "optimizer = [Optimizer.ADAM]\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "tfnet.describe_multi_label(seq['y'], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702efca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "tf.compat.v1.set_random_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "net = Network('study2_model').add_input_layer(n_cov, normalization=Normalization.Z_SCORE)\n",
    "net.add_lstm_layer(hidden[0], peepholes=True)\n",
    "\n",
    "net.begin_multi_output(cost_methods=[Cost.BINARY_CROSS_ENTROPY])\n",
    "net.add_dropout_layer(1, keep=keep[0], activation=tf.nn.sigmoid)\n",
    "net.end_multi_output()\n",
    "\n",
    "net.set_default_cost_method(Cost.CROSS_ENTROPY)\n",
    "net.set_optimizer(optimizer[0])\n",
    "\n",
    "net.train(x=seq['x'],\n",
    "          y=seq['y'],\n",
    "          step=step[0],\n",
    "          use_validation=True,\n",
    "          max_epochs=max_epochs, threshold=threshold[0], batch=batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6775b646",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.save_model_weights()      # comment to use a previously-saved model\n",
    "#\n",
    "# net.build()                 # uncomment to use previously-saved model\n",
    "# net.restore_model_weights() # uncomment to use previously-saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f3f9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('writing predictions to file...')\n",
    "du.write_csv(tfnet.flatten_sequence(np.array([np.array([t[-1]]) for t in net.predict(seqex['x'])[0]]),\n",
    "                                        seqex['key'].reshape((-1,3))), 'model_predictions.csv',\n",
    "             ['user_id','target_assignment_id','target_sequence_id','pcomplete'])\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4849bdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import graph_def_editor \n",
    "import warnings\n",
    "import time\n",
    "import csv\n",
    "import sys\n",
    "import os\n",
    "import pandas \n",
    "from sklearn.metrics import f1_score, r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from skll.metrics import kappa as kpa\n",
    "import pickle\n",
    "import psycopg2 as pg\n",
    "import functools\n",
    "import Levenshtein as lev\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "session_info.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4e9545",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.session.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
