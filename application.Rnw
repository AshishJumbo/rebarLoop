

<<loadPackages,include=FALSE,cache=FALSE>>=
library(scales)
library(ggplot2)
library(dplyr)
library(forcats)
library(loop.estimator)
source('code/loop_ols.R')
source('code/loop_ext.R')
@

<<loadData,include=FALSE,cache=FALSE>>=
source('code/dataPrep.r')
@

<<analysisFunctions,include=FALSE,cache=FALSE>>=
source('code/analysisFunctions.r')
@

<<runAnalysis,include=FALSE,cache=TRUE>>=
#fullres <- sapply(levels(dat$problem_set),full,simplify=FALSE)

#save(fullres,file='results/fullres.RData')
@

<<loadResults,include=FALSE,cache=FALSE>>=
load('results/fullres.RData')
rnk <- rank(sapply(fullres,function(x) x['simpDiff','se']))
names(fullres) <- LETTERS[rnk]
dat$ps <- LETTERS[rnk[as.character(dat$problem_set)]]

justSEs <- sapply(fullres,function(x) x[,'se'])
justImp <- round(sapply(fullres,function(x) x[,'improvement'])*100)
@

\begin{table}[ht]
\centering
\begin{tabular}{rlllllllllll}
\hline
<<sampleSize,results='asis',echo=FALSE>>=
ssTab <- table(dat$treatment,dat$ps)
cat('Experiment &',paste(LETTERS[1:11],collapse='&'),'\\\\\n')
cat('\\hline\n')
cat('$n_C$ &',paste(ssTab['0',LETTERS[1:11]],collapse='&'),'\\\\\n')
cat('$n_T$ &',paste(ssTab['1',LETTERS[1:11]],collapse='&'),'\\\\\n')
cat('\\hline\n')
cat('Experiment &',paste(LETTERS[12:22],collapse='&'),'\\\\\n')
cat('\\hline\n')
cat('$n_C$ &',paste(ssTab['0',LETTERS[12:22]],collapse='&'),'\\\\\n')
cat('$n_T$ &',paste(ssTab['1',LETTERS[12:22]],collapse='&'),'\\\\\n')
@
\hline
\end{tabular}
\caption{Sample Sizes for each of the 22 TestBed A/B Tests}
\label{tab:sampleSizes}
\end{table}






% \begin{itemize}
%  \item General structure: predicts what as a function of what?
%  \item briefly describe deep learning
%  \item describe a couple modeling choices
%  \item how was the model evaluated? (cross validation?)
% \end{itemize}
\subsection{Results}

In each of the 22 experiments, we calculated five different unbiased
ATE estimates:
\begin{enumerate}
 \item the simple difference \eqref{eq:tauSD}
\end{enumerate}
Two estimates using Deep Learning predictions from the remnant:
\begin{enumerate}
\setcounter{enumi}{2}
 \item rebar, i.e. the simple difference estimate with
    $Y-\pred$ replacing outcomes $Y$
 \item ReLOOP*, i.e. LOOP-OLS with $\pred$ as the only covariate
\end{enumerate}
Two estimates using TestBed covariates:
\begin{enumerate}
\setcounter{enumi}{4}
 \item LOOP using only covariates supplied within TestBed
 \item ReLOOP, using both $\pred$ and provided TestBed covariates
\end{enumerate}
Since each of these estimates is unbiased, we will focus on the
estimated standard errors.

\subsubsection{Simple Difference, Rebar, and LOOP}

<<makeGraphics,include=FALSE>>=
source('code/graphics.r')
@

\begin{figure}
\centering
\includegraphics[width=0.95\textwidth]{ses1.pdf}
\caption{Standard errors for four ATE estimates in each of the 22
  ASSISTments online experiments, in percentage point units. The experiments are ordered
  according to the standard error of the simple difference estimate.}
\label{fig:ses1}
\end{figure}

Figure \ref{fig:ses1} displays estimated standard errors from the
simple difference estimator, rebar, and ReLOOP*.

<<rebar,include=FALSE>>=
best <- colnames(justImp)[which.max(justImp['rebar',])]
badRebar1 <- colnames(justImp)[which.min(justImp['rebar',])]
ji <- justImp[,-which.min(justImp['rebar',])]
badRebar2 <- colnames(ji)[which.min(ji['rebar',])]
@

<<badReLOOP,include=FALSE>>=
badReLOOP1 <- -justImp['strat1',justSEs['strat1',]>justSEs['simpDiff',]]
badReLOOP <- -justImp['strat3',justSEs['strat3',]>justSEs['simpDiff',]]
@
%Within-sample covariance adjustment via LOOP improved precision in \Sexpr{sum(justSEs['justCovs',]<justSEs['simpDiff',])}

Rebar standard errors were lower than their simple difference
counterparts in \Sexpr{sum(justSEs['rebar',]<justSEs['simpDiff',])} of
the 22 experiments.
Notably, in one case (labeled experiment
``\Sexpr{best}'') rebar
reduced the simple difference standard error by approximately
\Sexpr{justImp['rebar',best]}\%.
On the other hand, in
\Sexpr{sum(justSEs['rebar',]>justSEs['simpDiff',])} experiments, rebar
increased the standard error, most egregiously in experiment%s
\Sexpr{badRebar1}% and \Sexpr{badRebar2}
, in which rebar increased
standard errors by a factor of
\Sexpr{justImp['rebar',badRebar1]}\%. % and
%\Sexpr{justImp['rebar',badRebar2]}\%, respectively.
In these cases, apparently, the imputations from the model fit to the
remnant were particularly inaccurate.
Because experimental outcomes played no role whatsoever in rebar
covariate adjustment, the adjustment was blind to this inaccuracy, and
was unable to anticipate the resulting increase in standard errors in
those cases.

In contrast, the ReLOOP* estimator incorporates information on
imputation accuracy into its covariate adjustment.
Across the board, ReLOOP* standard errors were smaller or roughly equal to
simple difference standard errors.
(In \Sexpr{sum(justSEs['strat1',]>justSEs['simpDiff',])} cases ReLOOP*
standard errors are very slightly larger, a factor of about \Sexpr{max(badReLOOP)}\%.)
In those cases in which rebar performed well, ReLOOP* tended to
perform even better.
For instance, in experiment \Sexpr{best}, ReLOOP* reduced the simple
difference standard errors by a factor of \Sexpr{justImp['strat1',best]}\%.



\subsubsection{Incorporating Standard Covariates}
\begin{figure}
\centering
\includegraphics[width=0.95\textwidth]{ses2.pdf}
\caption{Standard errors for three ATE estimates in each of the 22
  ASSISTments online experiments, in percentage point units. The experiments are ordered
  according to the standard error of the simple difference estimate.}
\label{fig:ses2}
\end{figure}


<<reloop,include=FALSE>>=
bestL <- colnames(justImp)[which.max(justImp['justCovs',])]
stopifnot(sum(justSEs['justCovs',]>justSEs['simpDiff',])==4)
@


Figure \ref{fig:ses2} shows standard errors for effect estimates that
incorporate within-sample covariate adjustment via LOOP, for ReLOOP
effect estimates that additionally incorporate remnant-based
predictions, and for simple difference estimates.
In most cases, the covariate adjustment in LOOP reduced standard
errors.
In some cases the reduction was substantial---in experiment
\Sexpr{bestL}, LOOP reduced standard errors by a factor of
\Sexpr{justImp[,bestL]}\%.
In four cases LOOP standard errors were slightly greater than simple
difference, though the difference was moderate or
small---\Sexpr{-min(justImp['justCovs',])}\% or less.

Across all 22 experiments, the standard errors for the ReLOOP
estimates were lower or roughly equal to standard errors for
the other estimates---in these datasets, ReLOOP indeed appears to have
incorporated the advantages of its constituent methods.
These gains in precision can have substantial practical benefit.
Figure \ref{fig:ssMult} expresses changes in standard errors in terms
of sample size---if the simple difference standard error is
$SE_{sd}$ and the ReLOOP standard error is $SE_{rl}$, then covariate
adjustment via ReLOOP is roughly equivalent to multiplying the sample
size by $SE_{sd}^2/SE_{rl}^2$.
The increases in precision due to ReLOOP were, in some cases,
equivalent to increasing the sample size by 50\% or more, and in one
case increasing the sample size by nearly 300\%.


\begin{figure}
\centering
\includegraphics[width=0.95\textwidth]{ssMult.pdf}
\caption{Increases in sample size equivalent to changes in standard
  error due to ReLOOP. That is, $SE_{sd}^2/SE_{rl}^2$, where $SE_{sd}$
  is the simple difference standard error and $SE_{rl}$ the ReLOOP standard error. }
\label{fig:ssMult}
\end{figure}



